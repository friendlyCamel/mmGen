# 利用单张深度相机快照实现通用的毫米波原始信号生成（mmGen code）

---

​        这项工作通过对毫米波信号的传播和反射过程进行建模，在计算机视觉模型等现有技术的辅助下，实现了从单张深度图到毫米波原始信号的重建。在我们的工作中，我们将人体和环境中的物体（例如桌子，白板，沙发等）建模为统一的mesh网格，而后通过对不同的物体的材质进行识别，为不同的反射表面赋予不同的反射系数，计算不同反射面的面积，法向量等系数，提高信号生成质量；我们设计了高反射概率平面（HRPP）来简化人体和环境中物体可能存在多径反射，减少了光线追踪的时间消耗；我们还为虚拟天线阵列拟合了其收发增益随角度变化的曲线，进一步提高在雷达视场边缘的物体的信号重建准确度。我们相信这类非深度学习模型辅助的生成方式具有更好的环境适应性，并且可以很方便的为下游任务模型训练提供预训练的数据集。

​        我们的工作被IEEE INFOCOM 2025接收，更多的细节可以翻阅我们的论文或是代码，我们的论文链接为：[mmGen](https://arxiv.org/abs/2503.21122)

![image-20250822134859105](C:\Users\LiHao\AppData\Roaming\Typora\typora-user-images\image-20250822134859105.png)

## 项目目录

---

**mmGen**

-- **examples** 

-- -- **raw_mmWave_human**

-- -- -- **captured signal**

-- -- --  -- **kinect** 

-- -- -- -- -- recoder.mkv                             *深度相机采集的场景监督*

-- -- -- -- -- time_log.txt                              *深度相机采集时的时间戳*

-- -- -- -- **out**                                                *借助视觉模型生成的人体mesh*

-- -- -- -- **rgb**                                                从视频中提取的RGB图片

-- -- -- -- adc.bin                                         *毫米波雷达采集的毫米波信号*

-- -- -- -- aligned_index.txt                       *毫米波帧与视频帧对齐的索引文件*

-- -- -- -- skeleton_LEFT_KNEE.npy         *深度相机辅助下的人体关节位置信息*

-- -- -- -- sys_sig0_1.npy                           *利用mmGen生成的毫米波信号*

-- -- final.obj                                             *用于信号合成的环境mesh*

-- -- scene1.mkv                                      *用于信号合成的深度相机数据*

-- **sources**                                                *用于信号生成的源文件*

-- -- config

-- -- eval_vis.py

-- -- pre_align.py

-- -- pre_pcd2mesh.py

-- -- preprocess_utils.py

-- -- radar_define.py

-- -- signal_generation.py

-- -- syn_define.py 

-- -- syn_functions.py

-- Hand4Whole_infer.py

-- requirements.txt

## 部署方法

---

### 准备工作

准备examples文件夹及其内容，下载链接：[examples](https://drive.google.com/file/d/1ZFlAdJdZ9Qlrh_R5NZGJptzqzA4rdVnC/view?usp=sharing)

#### 环境准备

新建一个conda虚拟环境并安装需要的软件包：

```
conda create -n mmGen python=3.9
conda activate mmGen
pip install -r requirements.txt
cd sources
```

#### 信号生成数据准备

为了生成原始毫米波信号，我们需要深度图及RGB图像帮助我们合成人体以及环境mesh。

##### 环境mesh准备

读取场景相关的mkv文件，将环境点云转换为场景mesh并保存为final.obj文件。

```
python pre_pcd2mesh.pv
```

- 该过程包括点云法线的估计，利用滚球算法生成mesh，点云空洞补全以及降采样，中间过程中会保留temp文件从而进行3D object detection.

部署用于3D物体检测的深度学习模型Votenet，记录下各个物体种类ID和边界框，部署方式：[Votenet](https://github.com/open-mmlab/mmdetection3d/tree/main/configs/votenet)

##### 人体mesh准备

读取人体相关的mkv文件，根据时间戳对齐毫米波和相机数据，而后借助人体mesh回归模型对人体网格进行回归。

```
python pre_align.py
```

- 该脚本按照时间戳对齐了RGB图像和利用雷达采集的毫米波帧，并在每帧中基于Kinect的人体捕捉模块，捕捉并记录人体的位置。

部署开源的人体mesh回归模型Hand4Whole，保存每帧的人体mesh为obj文件。部署方式：[Hand4Whole](https://github.com/mks0601/Hand4Whole_RELEASE)

- 我们提供了一个针对本工作而修改的推理脚本，在成功部署Hand4Whole模型后，可将Hand4Whole_infer.py脚本替换到其项目目录的demo文件夹下。
- 对于人体mesh网格的获取还有许多方式，例如我们在论文中提到的[Text to Motion](https://github.com/GuyTevet/motion-diffusion-model)方案。我们的工作支持类似的obj文件直接输入进mmGen中。

### 毫米波信号生成

在生成毫米波信号前，请确保此时项目目录中的final.obj，skeleton_LEFT_KNEE.npy和rgb目录下的人体obj文件均存在。

```
python signal_generation.py
```

- 在生成信号前，可在syn_define文件中设置vis变量，选择是否可视化毫米波信号生成时的虚拟场景。
- 脚本运行完毕后会在captured signal文件夹下生成sys_sig0_1.npy原始毫米波信号，在示例中，该信号为模拟IWR6843isk雷达采集的毫米波信号，包含45帧，在3发射天线和4接收天线的设置下发射255个chirp信号，每个chirp采样256个点。实采的毫米波雷达配置见config.py，模拟的雷达配置见syn_define.py

### 生成信号示例

原始毫米波信号是复杂的复数时间序列，无法直接可视化的展示，因此我们提供了一个可视化的评估脚本来真实生成的信号。

```
python eval_vis.py
```

- vis_range_compare 展示了生成信号的Range-FFT结果
- vis_micro_doppler 展示了微多普勒图的结果
- vis_RA 展示了Range-Angle谱图的结果
- vis_point_cloud 展示了点云的可视化结果

**Range谱图**

![range](D:\资料\文献\info25\range.gif)

**Range-Angle谱图**

<img src="D:\资料\文献\info25\ra.gif" alt="ra" style="zoom:60%;" />

**微多普勒图及点云**

<img src="D:/资料/文献/info25/micro-doppler.png" alt="micro" style="zoom:50%;" /><img src="D:\资料\文献\info25\pc.gif" alt="pc" style="zoom:50%;" />

# 鸣谢

我们的信号生成流程借鉴和使用了多个开源的项目作为辅助，因此如果您想要引用这项工作，我们很希望您也能引用这些开源项目。在这里向这些开源项目表示感谢！

```
@inproceedings{qi2019deep,
    author = {Qi, Charles R and Litany, Or and He, Kaiming and Guibas, Leonidas J},
    title = {Deep Hough Voting for 3D Object Detection in Point Clouds},
    booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
    year = {2019}
}
@InProceedings{Moon_2022_CVPRW_Hand4Whole,  
	author = {Moon, Gyeongsik and Choi, Hongsuk and Lee, Kyoung Mu},  
	title = {Accurate 3D Hand Pose Estimation for Whole-Body 3D Human Mesh Estimation},  
	booktitle = {Computer Vision and Pattern Recognition Workshop (CVPRW)},  
	year = {2022}  
}  
@inproceedings{tevet2023human,
	author={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or 	  and Amit Haim Bermano},
	title={Human Motion Diffusion Model},
	booktitle={The Eleventh International Conference on Learning Representations },
	year={2023},
	url={https://openreview.net/forum?id=SJ1kSyO2jwu}
}
@article{tevet2024closd,
	author={Tevet, Guy and Raab, Sigal and Cohan, Setareh and Reda, Daniele and Luo, 		Zhengyi and Peng, Xue Bin and Bermano, Amit H and van de Panne, Michiel},
	title={CLoSD: Closing the Loop between Simulation and Diffusion for multi-task 			character control},
	journal={arXiv preprint arXiv:2410.03441},
	year={2024}
}
```



# 引用

---

```
@inproceedings{huang2025one,
  title={One Snapshot is All You Need: A Generalized Method for mmWave Signal Generation},
  author={Huang, Teng and Ding, Han and Sun, Wenxin and Zhao, Cui and Wang, Ge and Wang, Fei and Zhao, Kun and Wang, Zhi and Xi, Wei},
  booktitle={IEEE INFOCOM 2025},
  year={2025}
}
```



